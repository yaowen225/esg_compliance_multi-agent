#!/usr/bin/env python3
"""
GRI Markdownè½‰JSONè½‰æ›å™¨
è§£æGRI markdownæª”æ¡ˆä¸¦è½‰æ›ç‚ºæ¨™æº–JSONæ ¼å¼
æ”¯æ´è‹±æ–‡å­—æ¯ç·¨è™Ÿï¼ˆa, b, c, dï¼‰å’Œç¾…é¦¬æ•¸å­—å­é …ç›®ï¼ˆi, ii, iii, iv, vï¼‰çš„åˆä½µ
åŒ…å«OCRåŠŸèƒ½è™•ç†è¢«éŒ¯èª¤è­˜åˆ¥ç‚ºåœ–ç‰‡çš„æ–‡å­—å…§å®¹
"""

import json
import re
import sys
import argparse
from pathlib import Path
import warnings

# OCRç›¸é—œimports
try:
    import pytesseract
    import cv2
    import numpy as np
    from PIL import Image
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    warnings.warn("OCRåŠŸèƒ½ä¸å¯ç”¨: è«‹å®‰è£ pytesseract, opencv-python-headless å’Œ Pillow")

class GRIMarkdownToJsonConverter:
    def __init__(self):
        self.section = ""
        self.groups = []
        self.ocr_reader = None
        
        # åˆå§‹åŒ–OCRé–±è®€å™¨ï¼ˆæ”¯æ´ä¸­æ–‡å’Œè‹±æ–‡ï¼‰
        if OCR_AVAILABLE:
            try:
                print("ğŸ”„ åˆå§‹åŒ–Tesseract OCR...")
                # æ¸¬è©¦tesseractæ˜¯å¦å¯ç”¨
                pytesseract.get_tesseract_version()
                self.ocr_available = True
                print("âœ… Tesseract OCRåˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸  Tesseractåˆå§‹åŒ–å¤±æ•—: {e}")
                print("ğŸ’¡ è«‹ç¢ºèªå·²å®‰è£Tesseractä¸¦æ­£ç¢ºè¨­å®šè·¯å¾‘")
                self.ocr_available = False
        else:
            print("âš ï¸  OCRåŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³éåœ–ç‰‡æ–‡å­—æå–")
            self.ocr_available = False
        
    def clean_text(self, text):
        """æ¸…ç†æ–‡å­—ï¼Œç§»é™¤å¤šé¤˜ç©ºæ ¼ã€æ˜Ÿè™Ÿæ¨™è¨˜å’Œæ›è¡Œ"""
        # ç§»é™¤markdownç²—é«”æ¨™è¨˜
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        # ç§»é™¤åˆ—è¡¨ç¬¦è™Ÿ
        text = re.sub(r'^[-â€¢]\s*', '', text.strip())
        # åˆä½µå¤šå€‹ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text
    
    def extract_section_number(self, content):
        """å¾å…§å®¹ä¸­æå–sectionç·¨è™Ÿ - å„ªå…ˆå¾æ­éœ²é …ç›®æ¨™é¡Œæå–"""
        
        # å„ªå…ˆç´š1: å¾æ­éœ²é …ç›®æ¨™é¡Œä¸­æå–ï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
        # åŒ¹é… "æ­éœ²é …ç›® **405-1**" æˆ– "æ­éœ²é …ç›® 405-1" æ ¼å¼
        disclosure_patterns = [
            r'æ­éœ²é …ç›®\s*\*\*(\d+)-\d+\*\*',    # æ­éœ²é …ç›® **405-1**
            r'æ­éœ²é …ç›®\s*(\d+)-\d+',             # æ­éœ²é …ç›® 405-1
            r'# æ­éœ²é …ç›®\s*\*\*(\d+)-\d+\*\*',   # # æ­éœ²é …ç›® **405-1**
            r'## æ­éœ²é …ç›®\s*\*\*(\d+)-\d+\*\*',  # ## æ­éœ²é …ç›® **405-1**
        ]
        
        for pattern in disclosure_patterns:
            match = re.search(pattern, content)
            if match:
                section_num = match.group(1)
                print(f"ğŸ¯ å¾æ­éœ²é …ç›®æ¨™é¡Œæå–section: {section_num}")
                return section_num
        
        # å„ªå…ˆç´š2: å¾ "GRI XXX" æ ¼å¼ä¸­æå–
        match = re.search(r'GRI\s+(\d+)', content)
        if match:
            section_num = match.group(1)
            print(f"ğŸ¯ å¾GRIæ¨™è¨˜æå–section: {section_num}")
            return section_num
        
        # å„ªå…ˆç´š3: å¾æª”æ¡ˆè·¯å¾‘ä¸­æå–ï¼ˆå¦‚æœå‰é¢çš„æ–¹æ³•éƒ½å¤±æ•—ï¼‰
        # å°‹æ‰¾è·¯å¾‘ä¸­çš„ "GRI 405" æ ¼å¼
        file_path_match = re.search(r'GRI\s+(\d+)', content)
        if file_path_match:
            section_num = file_path_match.group(1)
            print(f"ğŸ¯ å¾æª”æ¡ˆè·¯å¾‘æå–section: {section_num}")
            return section_num
        
        # å„ªå…ˆç´š4: å¾ä»»ä½• XXX-X æ ¼å¼ä¸­æå–sectionéƒ¨åˆ†
        match = re.search(r'(\d+)-\d+', content)
        if match:
            section_num = match.group(1)
            print(f"ğŸ¯ å¾ç·¨è™Ÿæ ¼å¼æå–section: {section_num}")
            return section_num
        
        # æœ€å¾Œå‚™æ¡ˆï¼šå°‹æ‰¾3ä½æ•¸ç·¨è™Ÿï¼ˆé¿å…åŒ¹é…å–®å€‹æ•¸å­—å¦‚"2"ï¼‰
        matches = re.findall(r'\b(\d{3,})\b', content)  # åªåŒ¹é…3ä½æˆ–ä»¥ä¸Šçš„æ•¸å­—
        for number in matches:
            if 200 <= int(number) <= 999:  # GRIæ¨™æº–çš„åˆç†ç¯„åœ
                print(f"ğŸ¯ å¾3ä½æ•¸ç·¨è™Ÿæå–section: {number}")
                return number
        
        # å¦‚æœéƒ½å¤±æ•—ï¼Œè¿”å›é è¨­å€¼ä¸¦è­¦å‘Š
        print("âš ï¸  ç„¡æ³•å¾å…§å®¹ä¸­æå–sectionç·¨è™Ÿï¼Œä½¿ç”¨é è¨­å€¼")
        return "000"
    
    def parse_markdown_content(self, content):
        """è§£æmarkdownå…§å®¹ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼ï¼ˆæ¨™æº–æ ¼å¼ã€OCRæ–‡å­—ã€æ··åˆæ ¼å¼ï¼‰"""
        lines = content.split('\n')
        
        # æå–sectionç·¨è™Ÿ
        self.section = self.extract_section_number(content)
        if self.section == "3":  # å¦‚æœåªæå–åˆ°"3"ï¼Œè¨­å®šç‚º"303"
            self.section = "303"
        
        print(f"ğŸ” è­˜åˆ¥section: {self.section}")
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # æ–¹æ³•1: æª¢æ¸¬æ¨™æº–æ ¼å¼æ­éœ²é …ç›®
            disclosure_match, title_text, disclosure_number = self.detect_standard_disclosure(line)
            if disclosure_match:
                print(f"ğŸ“‹ æ¨™æº–æ ¼å¼æ­éœ²é …ç›®: {disclosure_number}")
                items, next_i = self.extract_requirement_items(lines, i + 1, disclosure_number)
                
                if items:
                    group = {
                        "title": f"{disclosure_number} {title_text}",
                        "items": items
                    }
                    self.groups.append(group)
                    print(f"âœ… æå–äº† {len(items)} å€‹é …ç›®")
                
                i = next_i
                continue
            
            # æ–¹æ³•2: æª¢æ¸¬OCRæå–çš„æ–‡å­—
            if "**[å¾åœ–ç‰‡æå–çš„æ–‡å­—]**" in line:
                print(f"ğŸ–¼ï¸  ç™¼ç¾OCRæ–‡å­—å€å¡Š")
                ocr_items, next_i = self.extract_items_from_ocr_text_enhanced(lines, i)
                
                for item_group in ocr_items:
                    self.groups.append(item_group)
                    print(f"âœ… OCRæå–äº† {len(item_group['items'])} å€‹é …ç›®")
                
                i = next_i
                continue
            
            # æ–¹æ³•3: æª¢æ¸¬æ··åˆæ ¼å¼ï¼ˆmarkdown + ä¸æ¨™æº–æ ¼å¼ï¼‰
            mixed_match, mixed_items = self.detect_mixed_format_disclosure(lines, i)
            if mixed_match:
                for item_group in mixed_items:
                    self.groups.append(item_group)
                    print(f"âœ… æ··åˆæ ¼å¼æå–äº† {len(item_group['items'])} å€‹é …ç›®")
                i += 1
                continue
            
            i += 1
    
    def detect_standard_disclosure(self, line):
        """æª¢æ¸¬æ¨™æº–æ ¼å¼çš„æ­éœ²é …ç›®"""
        disclosure_patterns = [
            r'^#+\s*æ­éœ²é …ç›®\s*\*\*(\d+-\d+)\*\*\s*(.+)',   # ## æ­éœ²é …ç›® **303-1** æ¨™é¡Œ
            r'^#+\s*æ­éœ²é …ç›®\s*(\d+-\d+)\s*(.+)',           # ## æ­éœ²é …ç›® 303-1 æ¨™é¡Œ
            r'^æ­éœ²é …ç›®\s*\*\*(\d+-\d+)\*\*\s*(.+)',        # æ­éœ²é …ç›® **303-1** æ¨™é¡Œ
            r'^æ­éœ²é …ç›®\s*(\d+-\d+)\s*(.+)',                # æ­éœ²é …ç›® 303-1 æ¨™é¡Œ
            r'^\*\*(\d+-\d+)\*\*\s*(.+)',                   # **303-1** æ¨™é¡Œ
            r'^(\d+-\d+)\s*(.+)',                           # 303-1 æ¨™é¡Œ
        ]
        
        for pattern in disclosure_patterns:
            match = re.match(pattern, line)
            if match:
                disclosure_number = match.group(1)
                title_text = self.clean_text(match.group(2))
                return True, title_text, disclosure_number
        
        return False, None, None
    
    def extract_requirement_items(self, lines, start_index, disclosure_number):
        """æå–è¦æ±‚å€æ®µçš„é …ç›®"""
        items = []
        i = start_index
        in_requirements_section = False
        
        print(f"ğŸ” é–‹å§‹æå– {disclosure_number} çš„è¦æ±‚é …ç›®ï¼Œå¾è¡Œ {start_index} é–‹å§‹")
        
        # å°‹æ‰¾åˆ°ä¸‹ä¸€å€‹æ­éœ²é …ç›®æˆ–æ–‡ä»¶çµæŸ
        while i < len(lines):
            line = lines[i].strip()
            
            if i < start_index + 15:  # å¢åŠ èª¿è©¦è¼¸å‡ºç¯„åœ
                print(f"   è¡Œ {i}: {line[:100]}")
            
            # å¦‚æœé‡åˆ°ä¸‹ä¸€å€‹æ­éœ²é …ç›®ï¼Œåœæ­¢
            if self.is_new_disclosure_item(line):
                print(f"   é‡åˆ°æ–°æ­éœ²é …ç›®ï¼Œåœæ­¢æ–¼è¡Œ {i}")
                break
            
            # æª¢æŸ¥æ˜¯å¦é€²å…¥è¦æ±‚å€æ®µ
            if self.is_requirements_section_start(line):
                in_requirements_section = True
                print(f"   æ‰¾åˆ°è¦æ±‚å€æ®µé–‹å§‹ï¼Œè¡Œ {i}")
                i += 1
                continue
            
            # æª¢æ¸¬OCRæ–‡å­—å€å¡Š
            if "**[å¾åœ–ç‰‡æå–çš„æ–‡å­—]**" in line:
                print(f"   æ‰¾åˆ°OCRæ–‡å­—å€å¡Šï¼Œè¡Œ {i}")
                # è™•ç†OCRæ–‡å­—ä¸­çš„è¦æ±‚
                ocr_items, next_i = self.extract_items_from_ocr_text_enhanced(lines, i)
                for item_group in ocr_items:
                    items.extend(item_group['items'])
                    print(f"   å¾OCRæå–äº† {len(item_group['items'])} å€‹é …ç›®")
                i = next_i
                continue
            
            # å¦‚æœåœ¨è¦æ±‚å€æ®µä¸­ï¼Œæå–é …ç›®
            if in_requirements_section:
                # æª¢æŸ¥å½™ç·¨è¦æ±‚ - ä½†ä¸åœæ­¢ï¼Œç¢ºä¿æ‰€æœ‰é …ç›®éƒ½è¢«æ”¶é›†
                if re.search(r"^#+\s*å½™ç·¨è¦æ±‚", line):
                    print(f"   é‡åˆ°å½™ç·¨è¦æ±‚ï¼Œé€²è¡Œæœ€çµ‚é …ç›®å›æº¯æª¢æŸ¥ï¼Œè¡Œ {i}")
                    # å‘å‰å›æº¯æª¢æŸ¥æ˜¯å¦æœ‰éºæ¼çš„é …ç›®ï¼ˆæ“´å±•åˆ°hé …ç›®ï¼‰
                    for back_i in range(max(0, i-30), i):
                        back_line = lines[back_i].strip()
                        # æª¢æŸ¥æ˜¯å¦æœ‰æœªæ”¶é›†çš„æ¨™æº–é …ç›®æ ¼å¼
                        if re.search(r'^\s*-\s*\*\*[a-h]\.\*\*', back_line):
                            back_item, _ = self.extract_single_item_with_subitems(lines, back_i, disclosure_number)
                            if back_item and not any(existing['clause'] == back_item['clause'] for existing in items):
                                items.append(back_item)
                                print(f"   ğŸ”„ å›æº¯æ”¶é›†é …ç›®: {back_item['clause']}")
                        # ä¹Ÿæª¢æŸ¥æ·±å±¤ç¸®é€²é …ç›®æ ¼å¼ï¼ˆå¯èƒ½è¢«éºæ¼ï¼‰
                        elif re.search(r'^\s*[a-h]\.\s*', back_line) and disclosure_number in back_line:
                            back_item, _ = self.extract_single_item_with_subitems(lines, back_i, disclosure_number)
                            if back_item and not any(existing['clause'] == back_item['clause'] for existing in items):
                                items.append(back_item)
                                print(f"   ğŸ”„ å›æº¯æ”¶é›†æ·±å±¤é …ç›®: {back_item['clause']}")
                    
                    # å®Œæˆæ”¶é›†å¾Œåœæ­¢
                    print(f"   âœ… å®Œæˆå½™ç·¨è¦æ±‚å‰çš„é …ç›®æ”¶é›†ï¼Œåœæ­¢æ–¼è¡Œ {i}")
                    break
                
                # æª¢æŸ¥æ˜¯å¦é‡åˆ°å…¶ä»–å¼·çƒˆçµæŸä¿¡è™Ÿ
                if self.is_strong_section_end(line):
                    print(f"   è¦æ±‚å€æ®µçµæŸï¼Œè¡Œ {i}")
                    break
                
                # ç‰¹æ®Šè™•ç†ï¼šæª¢æŸ¥æ·±å±¤ç¸®é€²çµæ§‹ï¼ˆå¦‚403-9 açš„æƒ…æ³ï¼‰
                if self.is_deep_indented_item(lines, i, disclosure_number):
                    deep_item, next_index = self.extract_deep_indented_item(lines, i, disclosure_number)
                    if deep_item:
                        # é¿å…é‡è¤‡é …ç›®
                        if not any(existing['clause'] == deep_item['clause'] for existing in items):
                            items.append(deep_item)
                            print(f"   æå–æ·±å±¤ç¸®é€²é …ç›®: {deep_item['clause']}")
                        i = next_index - 1
                    i += 1
                    continue
                
                # æª¢æŸ¥å„ç¨®å¯èƒ½çš„é …ç›®æ ¼å¼ï¼Œä¸¦æå–å­é …ç›®
                item, next_index = self.extract_single_item_with_subitems(lines, i, disclosure_number)
                if item:
                    # é¿å…é‡è¤‡é …ç›®
                    if not any(existing['clause'] == item['clause'] for existing in items):
                        items.append(item)
                        print(f"   æå–é …ç›®: {item['clause']}")
                    i = next_index - 1  # èª¿æ•´ç´¢å¼•ï¼Œå› ç‚ºä¸‹é¢æœƒ i += 1
            
            i += 1
        
        print(f"ğŸ” çµæŸå‰æœ€çµ‚æª¢æŸ¥ï¼šæƒææ˜¯å¦æœ‰éºæ¼çš„é …ç›®")
        # æœ€çµ‚æª¢æŸ¥ï¼šå‘å¾Œæƒææ˜¯å¦æœ‰éºæ¼çš„fã€gã€hé …ç›®
        for final_i in range(start_index, min(len(lines), start_index + 100)):
            final_line = lines[final_i].strip()
            
            # æª¢æŸ¥æ–°çš„æ­éœ²é …ç›®æˆ–ç« ç¯€åˆ†éš”ç¬¦
            if self.is_new_disclosure_item(final_line) or re.search(r'^#+\s*(æŒ‡å¼•|èƒŒæ™¯)', final_line):
                break
                
            # æª¢æŸ¥éºæ¼çš„é …ç›®ï¼ˆç‰¹åˆ¥æ˜¯fã€gã€hï¼‰
            for pattern in [
                r'^\s*-\s*\*\*([f-h])\.\*\*\s*(.*)',  # - **f.** å…§å®¹
                r'^\s*\*\*([f-h])\.\*\*\s*(.*)',      # **f.** å…§å®¹
                r'^\s*([f-h])\.\s*(.*)',              # f. å…§å®¹
            ]:
                match = re.search(pattern, final_line)
                if match:
                    letter = match.group(1)
                    clause = f"{disclosure_number} {letter}"
                    
                    # æª¢æŸ¥æ˜¯å¦å·²ç¶“æ”¶é›†é
                    if not any(existing['clause'] == clause for existing in items):
                        content = match.group(2).strip()
                        # ç°¡å–®æ¸…ç†æ ¼å¼
                        content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)
                        
                        item = {
                            "clause": clause,
                            "query": content
                        }
                        items.append(item)
                        print(f"   ğŸ” æœ€çµ‚æª¢æŸ¥ç™¼ç¾é …ç›®: {clause} - {content[:50]}...")
                        
        print(f"âœ… {disclosure_number} ç¸½å…±æå–äº† {len(items)} å€‹é …ç›®")
        return items, i
    
    def is_new_disclosure_item(self, line):
        """æª¢æŸ¥æ˜¯å¦æ˜¯æ–°çš„æ­éœ²é …ç›®"""
        patterns = [
            r'^#+\s*æ­éœ²é …ç›®\s*\*\*\d+-\d+\*\*',
            r'^#+\s*æ­éœ²é …ç›®\s*\d+-\d+',
            r'^æ­éœ²é …ç›®\s*\*\*\d+-\d+\*\*',
            r'^æ­éœ²é …ç›®\s*\d+-\d+',
            r'^\*\*\d+-\d+\*\*\s+\S+'
        ]
        
        for pattern in patterns:
            if re.match(pattern, line):
                return True
        return False
    
    def is_requirements_section_start(self, line):
        """æª¢æŸ¥æ˜¯å¦æ˜¯è¦æ±‚å€æ®µçš„é–‹å§‹"""
        patterns = [
            r"è¦æ±‚",
            r"å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š",
            r"å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š.*è¦æ±‚",
            r"è¦æ±‚.*å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š"
        ]
        
        # ç‰¹æ®Šæª¢æŸ¥ï¼šé¿å…å°‡403-8 aé …ç›®èª¤åˆ¤ç‚ºè¦æ±‚å€æ®µ
        # å¦‚æœè¡ŒåŒ…å« "**a.**" æˆ– "**b.**" ç­‰é …ç›®æ¨™è¨˜ï¼Œä¸æ‡‰è©²è¢«èªç‚ºæ˜¯è¦æ±‚å€æ®µé–‹å§‹
        if re.search(r'\*\*[a-e]\.\*\*', line):
            return False
        
        for pattern in patterns:
            if re.search(pattern, line):
                return True
        return False
    
    def is_requirements_section_end(self, line):
        """æª¢æŸ¥æ˜¯å¦æ˜¯è¦æ±‚å€æ®µçš„çµæŸ"""
        end_patterns = [
            r"å»ºè­°",
            r"æŒ‡å¼•",
            r"èƒŒæ™¯",
            r"å½™ç·¨è¦æ±‚",
            r"^#+\s*(å»ºè­°|æŒ‡å¼•|èƒŒæ™¯)",
            r"^\d+\.\d+\s+"  # å¦‚ 2.1, 2.2 ç­‰ç·¨è™Ÿ
        ]
        
        for pattern in end_patterns:
            if re.search(pattern, line):
                return True
        return False
    
    def extract_single_item(self, line, disclosure_number):
        """å¾å–®è¡Œä¸­æå–é …ç›®ï¼ˆå¢å¼·ç‰ˆï¼Œæ”¯æ´æ›´å¤šæ ¼å¼è®ŠåŒ–ï¼‰"""
        # è·³éç©ºè¡Œ
        if not line.strip():
            return None
        
        # æ ¼å¼1: é–‹é ­æœ‰ a., b., c., d., e. (åŒ…æ‹¬ç²—é«”æ ¼å¼)
        patterns_start = [
            r'^\s*-\s*\*\*([a-e])\.\*\*\s+(.+)',       # - **a.** å…§å®¹
            r'^\s*-\s*([a-e])\.\s+(.+)',               # - a. å…§å®¹
            r'^\s*\*\*([a-e])\.\*\*\s+(.+)',           # **a.** å…§å®¹
            r'^\s*([a-e])\.\s+(.+)',                   # a. å…§å®¹
        ]
        
        for pattern in patterns_start:
            match = re.match(pattern, line)
            if match:
                clause_letter = match.group(1)
                query_text = self.clean_text(match.group(2))
                if query_text and len(query_text) > 5:
                    return {
                        "clause": f"{disclosure_number} {clause_letter}",
                        "query": query_text
                    }
        
        # æ ¼å¼2: çµå°¾æœ‰ a., b., c., d., e. (åŒ…æ‹¬ç²—é«”æ ¼å¼) - å¢å¼·ç‰ˆ
        patterns_end = [
            r'^\s*-\s*(.+?)\s+\*\*([a-e])\.\*\*\s*$',  # - å…§å®¹ **a.**
            r'^\s*-\s*(.+?)\s+([a-e])\.\s*$',          # - å…§å®¹ a.
            r'^\s*(.+?)\s+\*\*([a-e])\.\*\*\s*$',      # å…§å®¹ **a.**
            r'^\s*(.+?)\s+([a-e])\.\s*$',              # å…§å®¹ a.
            # æ–°å¢ï¼šè™•ç†å†’è™Ÿå¾Œé¢æ¥å­—æ¯ç·¨è™Ÿçš„æƒ…æ³
            r'^\s*-\s*(.+?)[ï¼š:]\s*\*\*([a-e])\.\*\*\s*$',  # - å…§å®¹: **a.**
            r'^\s*-\s*(.+?)[ï¼š:]\s*([a-e])\.\s*$',          # - å…§å®¹: a.
            # æ–°å¢ï¼šè™•ç†ç‰¹æ®Šçš„å†’è™Ÿå‰ç½®æ ¼å¼
            r'^\s*-?\s*#+?\s*(.+?)[ï¼š:]\s*\*\*([a-e])\.\*\*\s*$',  # #### å…§å®¹: **a.**
            r'^\s*-?\s*(.+?)[ï¼š:]\s*\*\*([a-e])\.\*\*\s*$',       # å…§å®¹: **a.**
            r'^\s*-?\s*(.+?)[ï¼š:]\s*([a-e])\.\s*$',               # å…§å®¹: a.
        ]
        
        for pattern in patterns_end:
            match = re.search(pattern, line)
            if match:
                query_text = self.clean_text(match.group(1))
                clause_letter = match.group(2)
                if query_text and len(query_text) > 5:
                    return {
                        "clause": f"{disclosure_number} {clause_letter}",
                        "query": query_text
                    }
        
        return None
    
    def extract_roman_subitem(self, line):
        """æå–ç¾…é¦¬æ•¸å­—å­é …ç›®çš„æ–‡å­—ï¼ˆå¢å¼·ç‰ˆï¼Œæ”¯æ´é–‹é ­å’Œçµå°¾ä½ç½®ï¼‰"""
        # åŒ¹é…ç¾…é¦¬æ•¸å­—æ ¼å¼ï¼Œæ”¯æ´é–‹é ­å’Œçµå°¾ä½ç½®
        patterns = [
            # é–‹é ­ä½ç½®çš„ç¾…é¦¬æ•¸å­—
            r'^\s*-\s*\*\*([ivx]+)\.\*\*\s+(.+?)ï¼›?$',      # - **i.** å…§å®¹ï¼›
            r'^\s*-\s*\*\*([ivx]+)\.\*\*\s+(.+?)$',         # - **i.** å…§å®¹
            r'^\s*\*\*([ivx]+)\.\*\*\s+(.+?)ï¼›?$',          # **i.** å…§å®¹ï¼›
            r'^\s*\*\*([ivx]+)\.\*\*\s+(.+?)$',             # **i.** å…§å®¹
            r'^\s*-\s*([ivx]+)\.\s+(.+?)ï¼›?$',              # - i. å…§å®¹ï¼›
            r'^\s*-\s*([ivx]+)\.\s+(.+?)$',                 # - i. å…§å®¹
            r'^\s*([ivx]+)\.\s+(.+?)ï¼›?$',                  # i. å…§å®¹ï¼›
            r'^\s*([ivx]+)\.\s+(.+?)$',                     # i. å…§å®¹
            
            # çµå°¾ä½ç½®çš„ç¾…é¦¬æ•¸å­— - æ–°å¢
            r'^\s*-\s*(.+?)\s+\*\*([ivx]+)\.\*\*\s*ï¼›?$',   # - å…§å®¹ **ii.**ï¼›
            r'^\s*-\s*(.+?)\s+\*\*([ivx]+)\.\*\*\s*$',      # - å…§å®¹ **ii.**
            r'^\s*(.+?)\s+\*\*([ivx]+)\.\*\*\s*ï¼›?$',       # å…§å®¹ **ii.**ï¼›
            r'^\s*(.+?)\s+\*\*([ivx]+)\.\*\*\s*$',          # å…§å®¹ **ii.**
            r'^\s*-\s*(.+?)\s+([ivx]+)\.\s*ï¼›?$',           # - å…§å®¹ ii.ï¼›
            r'^\s*-\s*(.+?)\s+([ivx]+)\.\s*$',              # - å…§å®¹ ii.
            r'^\s*(.+?)\s+([ivx]+)\.\s*ï¼›?$',               # å…§å®¹ ii.ï¼›
            r'^\s*(.+?)\s+([ivx]+)\.\s*$',                  # å…§å®¹ ii.
        ]
        
        for i, pattern in enumerate(patterns):
            match = re.match(pattern, line)
            if match:
                if i < 8:  # é–‹é ­ä½ç½®çš„æ¨¡å¼
                    roman_num = match.group(1)
                    content = self.clean_text(match.group(2))
                else:  # çµå°¾ä½ç½®çš„æ¨¡å¼
                    content = self.clean_text(match.group(1))
                    roman_num = match.group(2)
                
                # é©—è­‰æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ç¾…é¦¬æ•¸å­—ï¼ˆi, ii, iii, iv, vï¼‰
                if roman_num in ['i', 'ii', 'iii', 'iv', 'v']:
                    # ç§»é™¤çµå°¾çš„åˆ†è™Ÿï¼Œçµ±ä¸€æ ¼å¼
                    content = content.rstrip('ï¼›;')
                    return content
        
        return None
    
    def extract_single_item_with_subitems(self, lines, current_index, disclosure_number):
        """å¾å–®è¡Œä¸­æå–é …ç›®ï¼Œä¸¦æ”¶é›†å…¶å­é …ç›®ï¼ˆç¾…é¦¬æ•¸å­—ï¼‰- å¢å¼·ç‰ˆï¼Œæ”¯æ´æ¨™é¡Œæ ¼å¼"""
        line = lines[current_index].strip()
        
        # è·³éç©ºè¡Œ
        if not line.strip():
            return None, current_index + 1
        
        # ç‰¹æ®Šè™•ç†ï¼š403-8 a é€™ç¨®æ ¼å¼ "æè¿°: **a.**"
        special_403_8_match = re.search(r'^-\s*(.+?)[ï¼š:]\s*\*\*([a-e])\.\*\*\s*$', line)
        if special_403_8_match and disclosure_number == "403-8":
            main_content = self.clean_text(special_403_8_match.group(1))
            clause_letter = special_403_8_match.group(2)
            
            print(f"   ğŸ¯ æ‰¾åˆ°403-8ç‰¹æ®Šæ ¼å¼ä¸»é …ç›®: {disclosure_number} {clause_letter} - {main_content[:50]}...")
            
            # æ”¶é›†ç¸®é€²çš„ç¾…é¦¬æ•¸å­—å­é …ç›®
            subitems = []
            i = current_index + 1
            
            while i < len(lines):
                subline = lines[i].strip()
                original_line = lines[i]
                
                # è·³éç©ºè¡Œ
                if not subline:
                    i += 1
                    continue
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯ç¸®é€²çš„ç¾…é¦¬æ•¸å­—å­é …ç›®
                if original_line.startswith('\t'):
                    # ç‰¹æ®Šè™•ç†ï¼šæå– "æè¿°; **i.**" æ ¼å¼
                    roman_match = re.search(r'^(.+?);\s*\*\*([ivx]+)\.\*\*\s*$', subline)
                    if roman_match:
                        subitem_content = self.clean_text(roman_match.group(1))
                        roman_num = roman_match.group(2)
                        
                        if roman_num in ['i', 'ii', 'iii', 'iv', 'v']:
                            subitems.append(subitem_content)
                            print(f"     ğŸ“Œ 403-8å­é …ç›®: {subitem_content[:50]}...")
                            i += 1
                            continue
                    
                    # æ¨™æº–çš„ç¾…é¦¬æ•¸å­—æå–
                    subitem_text = self.extract_roman_subitem(subline)
                    if subitem_text:
                        subitems.append(subitem_text)
                        print(f"     ğŸ“Œ æ¨™æº–å­é …ç›®: {subitem_text[:50]}...")
                        i += 1
                        continue
                
                # æª¢æŸ¥æ˜¯å¦é‡åˆ°æ–°çš„ä¸»é …ç›®æˆ–å…¶ä»–åœæ­¢æ¢ä»¶
                if (self.is_main_item(subline) or 
                    self.is_new_disclosure_item(subline) or 
                    self.is_strong_section_end(subline)):
                    print(f"     â¹ï¸  403-8åœæ­¢æ”¶é›†ï¼Œé‡åˆ°: {subline[:50]}...")
                    break
                
                i += 1
            
            # çµ„åˆæœ€çµ‚çµæœ
            if subitems:
                subitems_text = "ã€".join(subitems)
                final_query = f"{main_content}ï¼š{subitems_text}"
            else:
                final_query = main_content
            
            item = {
                "clause": f"{disclosure_number} {clause_letter}",
                "query": final_query
            }
            
            print(f"   âœ… 403-8ç‰¹æ®Šæ ¼å¼åˆä½µçµæœ: {item['query']}")
            return item, i
        
        # æ–°å¢ï¼šæ”¯æ´æ¨™é¡Œæ ¼å¼çš„é …ç›®ï¼ˆå¦‚ ### **a.** æˆ– #### **b.**ï¼‰
        title_item_match = re.search(r'^#+\s*\*\*([a-h])\.\*\*\s*(.+)', line)
        if title_item_match:
            clause_letter = title_item_match.group(1)
            main_content = self.clean_text(title_item_match.group(2))
            
            print(f"   ğŸ¯ æ‰¾åˆ°æ¨™é¡Œæ ¼å¼é …ç›®: {disclosure_number} {clause_letter} - {main_content[:50]}...")
            
            item = {
                "clause": f"{disclosure_number} {clause_letter}",
                "query": main_content
            }
            
            print(f"   âœ… æ¨™é¡Œæ ¼å¼é …ç›®: {item['query']}")
            return item, current_index + 1
        
        # æ¨™æº–çš„é …ç›®æå–é‚è¼¯
        item = self.extract_single_item(line, disclosure_number)
        if not item:
            return None, current_index + 1
        
        print(f"   ğŸ¯ æ‰¾åˆ°ä¸»é …ç›®: {item['clause']} - {item['query'][:50]}...")
        
        # å¦‚æœæ‰¾åˆ°äº†ä¸»é …ç›®ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰å­é …ç›®ï¼ˆç¾…é¦¬æ•¸å­—ï¼‰
        subitems = []
        i = current_index + 1
        
        # æ”¶é›†å­é …ç›® - å¢å¼·ç‰ˆé‚è¼¯
        while i < len(lines):
            subline = lines[i].strip()
            
            # è·³éç©ºè¡Œ
            if not subline:
                i += 1
                continue
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯ç¸®é€²çš„ç¾…é¦¬æ•¸å­—å­é …ç›®ï¼ˆtabç¸®é€²ã€å¤šå€‹ç©ºæ ¼ç¸®é€²ã€æˆ–å¤šå±¤ç¸®é€²ï¼‰
            original_line = lines[i]
            is_indented = (original_line.startswith('\t') or 
                          original_line.startswith('    ') or
                          original_line.startswith('\t\t') or
                          original_line.startswith('        '))  # 8å€‹ç©ºæ ¼ä¹Ÿç®—ç¸®é€²
            
            if is_indented and subline:
                subitem_text = self.extract_roman_subitem(subline)
                if subitem_text:
                    subitems.append(subitem_text)
                    print(f"     ğŸ“Œ å­é …ç›®(ç¸®é€²): {subitem_text[:50]}...")
                    i += 1
                    continue
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯éç¸®é€²çš„ç¾…é¦¬æ•¸å­—å­é …ç›®
            subitem_text = self.extract_roman_subitem(subline)
            if subitem_text:
                subitems.append(subitem_text)
                print(f"     ğŸ“Œ å­é …ç›®(éç¸®é€²): {subitem_text[:50]}...")
                i += 1
                continue
            
            # æ”¹é€²åœæ­¢æ¢ä»¶ï¼šåªæœ‰åœ¨é‡åˆ°æ˜ç¢ºçš„æ–°ä¸»é …ç›®æ™‚æ‰åœæ­¢
            # ä¸è¦è¢«æ¨™é¡Œã€æŒ‡å¼•ç­‰ä¸­æ–·
            if self.is_main_item(subline):
                print(f"     â¹ï¸  åœæ­¢æ”¶é›†å­é …ç›®ï¼Œé‡åˆ°æ–°ä¸»é …ç›®: {subline[:50]}...")
                break
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°çš„æ­éœ²é …ç›®
            if self.is_new_disclosure_item(subline):
                print(f"     â¹ï¸  åœæ­¢æ”¶é›†å­é …ç›®ï¼Œé‡åˆ°æ–°æ­éœ²é …ç›®: {subline[:50]}...")
                break
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯è¦æ±‚å€æ®µçµæŸï¼ˆä½†è¦æ›´è¬¹æ…ï¼‰
            if self.is_strong_section_end(subline):
                print(f"     â¹ï¸  åœæ­¢æ”¶é›†å­é …ç›®ï¼Œé‡åˆ°å¼·çƒˆå€æ®µçµæŸä¿¡è™Ÿ: {subline[:50]}...")
                break
            
            i += 1
        
        # å¦‚æœæœ‰å­é …ç›®ï¼Œå°‡å®ƒå€‘åˆä½µåˆ°ä¸»é …ç›®çš„queryä¸­
        if subitems:
            print(f"   ğŸ”— åˆä½µ {len(subitems)} å€‹å­é …ç›®åˆ°ä¸»é …ç›®")
            # å°‡å­é …ç›®ç”¨"ã€"é€£æ¥
            subitems_text = "ã€".join(subitems)
            
            # æ‰¾åˆ°åˆé©çš„ä½ç½®æ’å…¥å­é …ç›®
            main_query = item['query']
            
            # æ ¹æ“šä¸åŒæƒ…æ³çµ„åˆæœ€çµ‚çš„query
            if "ä¸¦æŒ‰ä»¥ä¸‹ä¾†æº" in main_query:
                item['query'] = re.sub(r'ä¸¦æŒ‰ä»¥ä¸‹ä¾†æº[^ã€‚]*', f'ä¸¦æŒ‰{subitems_text}', main_query)
            elif "ä¸¦æŒ‰ä»¥ä¸‹çµ‚é»é¡åˆ¥" in main_query:
                item['query'] = re.sub(r'ä¸¦æŒ‰ä»¥ä¸‹çµ‚é»é¡åˆ¥[^ã€‚]*', f'ä¸¦æŒ‰{subitems_text}', main_query)
            elif "åŒ…æ‹¬ï¼š" in main_query or "åŒ…æ‹¬:" in main_query:
                item['query'] = re.sub(r'åŒ…æ‹¬ï¼š?', f'åŒ…æ‹¬{subitems_text}', main_query)
            elif "åŒ…æ‹¬æ˜¯å¦" in main_query:
                # é‡å°403-1çš„ç‰¹æ®Šæƒ…æ³ï¼šåŒ…æ‹¬æ˜¯å¦: **a.**
                item['query'] = re.sub(r'åŒ…æ‹¬æ˜¯å¦[ï¼š:]?\s*$', f'åŒ…æ‹¬æ˜¯å¦{subitems_text}', main_query)
            elif main_query.endswith(':') or main_query.endswith('ï¼š'):
                # åœ¨å†’è™Ÿå¾Œæ’å…¥å­é …ç›®
                item['query'] = main_query + f'{subitems_text}'
            elif "ç´°åˆ†ç¸½é‡" in main_query:
                item['query'] = re.sub(r'ç´°åˆ†ç¸½é‡', f'æŒ‰{subitems_text}ç´°åˆ†ç¸½é‡', main_query)
            elif main_query.endswith('(è‹¥é©ç”¨):') or main_query.endswith('ï¼ˆè‹¥é©ç”¨ï¼‰:'):
                item['query'] = re.sub(r'\(?è‹¥é©ç”¨\)?:', f'ï¼Œä¸¦æŒ‰{subitems_text}ç´°åˆ†(è‹¥é©ç”¨)', main_query)
            else:
                # åœ¨å¥å­æœ«å°¾æ·»åŠ å­é …ç›®
                if main_query.endswith('ã€‚'):
                    item['query'] = main_query[:-1] + f'ï¼ŒåŒ…æ‹¬{subitems_text}ã€‚'
                else:
                    item['query'] = main_query + f':{subitems_text}'
            
            print(f"   âœ… åˆä½µçµæœ: {item['query']}")
        
        return item, i
    
    def is_main_item(self, line):
        """æª¢æŸ¥æ˜¯å¦æ˜¯ä¸»é …ç›®ï¼ˆa., b., c., d., e.ï¼‰- æ”¯æ´å¤šç¨®æ ¼å¼"""
        # æª¢æŸ¥æ¨™æº–åˆ—è¡¨æ ¼å¼çš„é …ç›®æ¨™è¨˜
        standard_formats = (
            re.search(r'\*\*[a-e]\.\*\*', line) is not None or 
            re.search(r'^[a-e]\.\s+', line) is not None or 
            re.search(r'[a-e]\.$', line) is not None
        )
        
        # æª¢æŸ¥æ¨™é¡Œæ ¼å¼çš„é …ç›®æ¨™è¨˜ï¼ˆå¦‚ ### **a.** æˆ– #### **b.**ï¼‰
        title_formats = re.search(r'^#+\s*\*\*[a-e]\.\*\*', line) is not None
        
        return standard_formats or title_formats
    
    def extract_text_from_image(self, image_path):
        """ä½¿ç”¨Tesseract OCRå¾åœ–ç‰‡ä¸­æå–æ–‡å­—ï¼ˆé‡å°æ¢ç›®é …ç›®å„ªåŒ–ï¼‰"""
        if not self.ocr_available or not OCR_AVAILABLE:
            return ""
        
        try:
            print(f"ğŸ” æ­£åœ¨å¾åœ–ç‰‡æå–æ–‡å­—: {image_path}")
            
            # è®€å–åœ–ç‰‡
            image = cv2.imread(str(image_path))
            if image is None:
                print(f"âŒ ç„¡æ³•è®€å–åœ–ç‰‡: {image_path}")
                return ""
            
            # åœ–ç‰‡é è™•ç†ä»¥æé«˜OCRæ•ˆæœ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # é™å™ªè™•ç†
            denoised = cv2.medianBlur(gray, 5)
            
            # äºŒå€¼åŒ–è™•ç†
            _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # å½¢æ…‹å­¸æ“ä½œå»é™¤å™ªé»
            kernel = np.ones((1, 1), np.uint8)
            cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            
            # è½‰æ›ç‚ºPIL Imageæ ¼å¼
            pil_image = Image.fromarray(cleaned)
            
            # è¨­å®šTesseracté…ç½®
            # ä½¿ç”¨ç¹é«”ä¸­æ–‡å’Œè‹±æ–‡ï¼Œå„ªåŒ–ç‚ºæ–‡å­—è¡Œè­˜åˆ¥
            config = '--oem 3 --psm 6 -l chi_tra+eng'
            
            # ä½¿ç”¨Tesseractæå–æ–‡å­—
            extracted_text = pytesseract.image_to_string(pil_image, config=config)
            
            if extracted_text.strip():
                # æ¸…ç†æå–çš„æ–‡å­—
                cleaned_text = self.clean_ocr_text(extracted_text)
                print(f"âœ… æˆåŠŸæå–æ–‡å­—ï¼ˆ{len(cleaned_text)}å­—å…ƒï¼‰")
                print(f"   å‰100å­—å…ƒ: {cleaned_text[:100]}{'...' if len(cleaned_text) > 100 else ''}")
                return cleaned_text
            else:
                print(f"âš ï¸  æœªèƒ½å¾åœ–ç‰‡ä¸­æå–åˆ°æ–‡å­—")
                return ""
                
        except Exception as e:
            print(f"âŒ OCRè™•ç†å¤±æ•—: {e}")
            return ""
    
    def clean_ocr_text(self, text):
        """æ¸…ç†Tesseract OCRæå–çš„æ–‡å­—"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½è¡Œ
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        # ä¿®å¾©å¸¸è¦‹çš„OCRéŒ¯èª¤
        cleaned_lines = []
        for line in lines:
            # ä¿®å¾©å¸¸è¦‹éŒ¯èª¤
            line = line.replace('è¡è²', 'è¡æ“Š')
            line = line.replace('è¡ç¹«', 'è¡æ“Š') 
            line = line.replace('è¡è»—', 'è¡æ“Š')
            line = line.replace('é—œä¿‚å…¥', 'é—œä¿‚äºº')
            line = line.replace('åˆ©é›ªé—œä¿‚äºº', 'åˆ©å®³é—œä¿‚äºº')
            line = line.replace('æ¨™ç«¿', 'æ¨™æº–')
            line = line.replace('ä¾‹å¥³å£', 'ä¾‹å¦‚')
            line = line.replace('åœ‹è±•', 'åœ‹å®¶')
            line = line.replace('åœ˜éš›', 'åœ‹éš›')
            
            # æ¨™æº–åŒ–æ¨™é»ç¬¦è™Ÿ
            line = line.replace('. ', 'ã€‚')
            line = line.replace(', ', 'ï¼Œ')
            line = line.replace(': ', 'ï¼š')
            line = line.replace('; ', 'ï¼›')
            
            # æ¸…ç†å¤šé¤˜ç©ºæ ¼
            line = re.sub(r'\s+', ' ', line).strip()
            
            if len(line) > 2:  # éæ¿¾å¤ªçŸ­çš„è¡Œ
                cleaned_lines.append(line)
        
        # é‡æ–°çµ„ç¹”æ–‡å­—ï¼Œä¿æŒæ®µè½çµæ§‹
        result = '\n'.join(cleaned_lines)
        
        # ç‰¹åˆ¥è™•ç†ï¼šç¢ºä¿"è¦æ±‚"éƒ¨åˆ†æ ¼å¼æ­£ç¢º
        if 'è¦æ±‚' in result and 'å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š' in result:
            result = re.sub(r'è¦æ±‚.*?å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š', 'è¦æ±‚ï¼šå ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š', result)
        
        return result
    
    def organize_ocr_text_enhanced(self, text_blocks):
        """å¢å¼·ç‰ˆOCRæ–‡å­—çµ„ç¹”ï¼Œé‡å°æ¢ç›®é …ç›®å„ªåŒ–"""
        if not text_blocks:
            return ""
        
        print(f"ğŸ”§ çµ„ç¹” {len(text_blocks)} å€‹æ–‡å­—å¡Š...")
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰é‡è¦å…§å®¹
        important_blocks = []
        for block in text_blocks:
            text = block['text']
            is_important = block.get('is_important', False)
            
            if is_important:
                print(f"   ğŸ¯ é‡è¦å…§å®¹: {text} (ç½®ä¿¡åº¦: {block['confidence']:.3f})")
                important_blocks.append(block)
        
        # åˆ†æä¸¦é‡çµ„æ–‡å­—
        organized_parts = []
        
        # å°‹æ‰¾è¦æ±‚éƒ¨åˆ†
        has_requirement = any('è¦æ±‚' in block['text'] for block in important_blocks)
        if has_requirement:
            organized_parts.append("è¦æ±‚ï¼šå ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Šï¼š")
        
        # ç‰¹åˆ¥è™•ç†aé …ç›®ï¼ˆçµ„ç¹”å·²é‘‘åˆ¥ï¼‰
        a_content = None
        for block in important_blocks:
            if 'çµ„ç¹”å·²é‘‘åˆ¥' in block['text']:
                # ä¿®å¾©OCRéŒ¯èª¤ä¸¦æ ¼å¼åŒ–
                content = block['text'].replace('è¡è²', 'è¡æ“Š').replace(',', 'ï¼Œ')
                if not content.startswith('a.'):
                    content = 'a. ' + content
                a_content = content
                break
        
        if a_content:
            organized_parts.append(a_content)
        
        # ç‰¹åˆ¥è™•ç†bé …ç›®
        b_content = None
        b_parts = []
        
        # å°‹æ‰¾bé …ç›®æ¨™è¨˜
        has_b_marker = any('b.' in block['text'] for block in important_blocks)
        
        # æ”¶é›†bé …ç›®ç›¸é—œå…§å®¹
        for block in important_blocks:
            text = block['text']
            if ('åˆ©å®³é—œä¿‚äºº' in text or 'å¤–éƒ¨æ¨™' in text or 'åœ‹éš›æ¨™æº–' in text) and 'b.' not in text:
                b_parts.append(text.replace('è¡è²', 'è¡æ“Š').replace(',', 'ï¼Œ'))
        
        if has_b_marker and b_parts:
            b_content = 'b. ' + 'ï¼Œ'.join(b_parts)
            organized_parts.append(b_content)
        
        result = '\n'.join(organized_parts)
        print(f"ğŸ“ æœ€çµ‚çµ„ç¹”çµæœ: {result}")
        return result
    
    def format_ocr_output_enhanced(self, lines):
        """å¢å¼·ç‰ˆOCRè¼¸å‡ºæ ¼å¼åŒ–ï¼Œé‡å°æ¢ç›®é …ç›®å„ªåŒ–"""
        formatted_parts = []
        
        for line in lines:
            # ç‰¹æ®Šè™•ç†è¦æ±‚è¡Œ
            if line.startswith('è¦æ±‚'):
                formatted_parts.append('è¦æ±‚ï¼šå ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Šï¼š')
            # è™•ç†é …ç›®è¡Œ - å¢å¼·ç‰ˆæ¢ç›®æª¢æ¸¬
            elif re.search(r'[a-e]\.\s*', line):
                # ç¢ºä¿æ¢ç›®æ ¼å¼æ­£ç¢º
                # å°‡ "çµ„ç¹”å·²é‘‘åˆ¥çš„é‡å¤§é–“æ¥ç¶“æ¿Ÿè¡è²ä¾‹å­,åŒ…æ‹¬æ­£é¢èˆ‡è² é¢çš„è¡è²." 
                # æ ¼å¼åŒ–ç‚º "a. çµ„ç¹”å·²é‘‘åˆ¥çš„é‡å¤§é–“æ¥ç¶“æ¿Ÿè¡æ“Šä¾‹å­ï¼ŒåŒ…æ‹¬æ­£é¢èˆ‡è² é¢çš„è¡æ“Šã€‚"
                
                # ä¿®å¾©OCRå¸¸è¦‹éŒ¯èª¤
                line = line.replace('è¡è²', 'è¡æ“Š')
                line = line.replace(',', 'ï¼Œ')
                line = line.replace('.', 'ã€‚')
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«aé …ç›®å…§å®¹
                if 'çµ„ç¹”å·²é‘‘åˆ¥' in line and 'a.' not in line:
                    line = 'a. ' + line
                
                formatted_parts.append(line)
            # è™•ç†æŒ‡å¼•è¡Œï¼ˆé€šå¸¸å¿½ç•¥ï¼Œå› ç‚ºä¸åœ¨è¦æ±‚ç¯„åœå…§ï¼‰
            elif line.startswith('æŒ‡å¼•'):
                break  # åœæ­¢è™•ç†ï¼Œå› ç‚ºå·²ç¶“è¶…å‡ºè¦æ±‚ç¯„åœ
            # å…¶ä»–è¡Œå¯èƒ½æ˜¯é …ç›®çš„å»¶çºŒ
            else:
                if formatted_parts and not formatted_parts[-1].startswith('è¦æ±‚'):
                    # åˆä½µåˆ°ä¸Šä¸€è¡Œ
                    formatted_parts[-1] += ' ' + line
                else:
                    formatted_parts.append(line)
        
        result = '\n'.join(formatted_parts)
        print(f"ğŸ“ æ ¼å¼åŒ–çµæœ: {result}")
        return result
    
    def is_line_start_marker(self, text):
        """æª¢æŸ¥æ˜¯å¦æ˜¯è¡Œé–‹å§‹æ¨™è¨˜"""
        line_start_patterns = [
            r'^è¦æ±‚\s*[ï¼š:]?',      # è¦æ±‚:
            r'^[a-e]\.\s*',         # a. b. c.
            r'^æŒ‡å¼•\s*[ï¼š:]?',      # æŒ‡å¼•:
            r'^æ­éœ²é …ç›®',           # æ­éœ²é …ç›®
        ]
        
        for pattern in line_start_patterns:
            if re.match(pattern, text):
                return True
        return False
    
    def should_continue_line(self, text, current_line):
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²ç¹¼çºŒç•¶å‰è¡Œ"""
        # å¦‚æœç•¶å‰è¡Œæ˜¯ç©ºçš„ï¼Œä¸ç¹¼çºŒ
        if not current_line.strip():
            return False
        
        # å¦‚æœæ–‡å­—æ˜¯æ–°çš„é‡è¦æ¨™è¨˜ï¼Œä¸ç¹¼çºŒ
        if self.is_line_start_marker(text):
            return False
        
        # å¦‚æœç•¶å‰è¡Œå·²ç¶“æ˜¯å®Œæ•´çš„é …ç›®æ ¼å¼ï¼Œæª¢æŸ¥æ˜¯å¦æ‡‰è©²ç¹¼çºŒ
        if re.match(r'^[a-e]\.\s*', current_line):
            # å¦‚æœæ–‡å­—çœ‹èµ·ä¾†æ˜¯é …ç›®å…§å®¹çš„å»¶çºŒï¼Œç¹¼çºŒ
            if not re.match(r'^[a-e]\.\s*', text) and not text.startswith('æŒ‡å¼•'):
                return True
        
        # å¦‚æœç•¶å‰è¡Œæ˜¯"è¦æ±‚"é–‹é ­ï¼Œç¹¼çºŒæ”¶é›†ç›¸é—œå…§å®¹
        if current_line.startswith('è¦æ±‚'):
            if not self.is_line_start_marker(text):
                return True
        
        return False
    
    def fix_ocr_errors(self, text):
        """ä¿®å¾©å¸¸è¦‹çš„OCRéŒ¯èª¤"""
        # å¸¸è¦‹éŒ¯èª¤æ›¿æ›
        corrections = {
            'è¡è²': 'è¡æ“Š',
            'è¡ç¹«': 'è¡æ“Š', 
            'è¡è»—': 'è¡æ“Š',
            'é—œä¿‚å…¥': 'é—œä¿‚äºº',
            'åˆ©é›ªé—œä¿‚äºº': 'åˆ©å®³é—œä¿‚äºº',
            'æ¨™ç«¿': 'æ¨™æº–',
            'å”å®š': 'å”å®š',
            'ä¾‹å¥³å£': 'ä¾‹å¦‚',
            'åœ‹è±•': 'åœ‹å®¶',
            'åœ˜éš›': 'åœ‹éš›',
            'æ¨™ç«¿': 'æ¨™æº–',
            '. ': 'ã€‚',  # ä¿®å¾©å¥è™Ÿ
            ', ': 'ï¼Œ',  # ä¿®å¾©é€—è™Ÿ
            ': ': 'ï¼š',  # ä¿®å¾©å†’è™Ÿ
        }
        
        fixed_text = text
        for wrong, correct in corrections.items():
            fixed_text = fixed_text.replace(wrong, correct)
        
        # æ¸…ç†å¤šé¤˜ç©ºæ ¼
        fixed_text = re.sub(r'\s+', ' ', fixed_text).strip()
        
        return fixed_text
    
    def process_images_in_markdown(self, md_file_path):
        """è™•ç†markdownä¸­çš„åœ–ç‰‡ï¼Œä½¿ç”¨Tesseract OCRæå–æ–‡å­—ä¸¦ç›´æ¥ä¿®æ”¹åŸå§‹æ–‡ä»¶"""
        print(f"ğŸ” é–‹å§‹è™•ç†åœ–ç‰‡ï¼Œæª”æ¡ˆ: {md_file_path}")
        print(f"ğŸ” Tesseract OCR ç‹€æ…‹: {self.ocr_available}")
        print(f"ğŸ” OCR_AVAILABLE: {OCR_AVAILABLE}")
        
        if not self.ocr_available:
            print("âŒ Tesseract OCR æœªåˆå§‹åŒ–ï¼Œè·³éåœ–ç‰‡è™•ç†")
            return False
        
        # æ‰¾åˆ°markdownæª”æ¡ˆæ‰€åœ¨çš„ç›®éŒ„
        md_dir = Path(md_file_path).parent
        print(f"ğŸ” æª”æ¡ˆç›®éŒ„: {md_dir}")
        
        # è®€å–åŸå§‹å…§å®¹
        with open(md_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"ğŸ” æª”æ¡ˆå…§å®¹é•·åº¦: {len(content)}")
        
        # å°‹æ‰¾åœ–ç‰‡å¼•ç”¨çš„æ¨¡å¼
        image_pattern = r'!\[\]\(([^)]+\.(?:jpeg|jpg|png|gif))\)'
        
        # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡å¼•ç”¨
        matches = re.findall(image_pattern, content)
        print(f"ğŸ” æ‰¾åˆ°çš„åœ–ç‰‡å¼•ç”¨: {matches}")
        
        if not matches:
            print("â„¹ï¸  æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡å¼•ç”¨ï¼Œè·³éOCRè™•ç†")
            return False
        
        modified = False
        
        def replace_image_with_text(match):
            nonlocal modified
            image_filename = match.group(1)
            image_path = md_dir / image_filename
            
            print(f"ğŸ” è™•ç†åœ–ç‰‡: {image_filename}")
            print(f"ğŸ” åœ–ç‰‡è·¯å¾‘: {image_path}")
            print(f"ğŸ” åœ–ç‰‡å­˜åœ¨: {image_path.exists()}")
            
            if image_path.exists():
                # æå–åœ–ç‰‡ä¸­çš„æ–‡å­—
                print(f"ğŸ”„ é–‹å§‹OCRè™•ç†...")
                extracted_text = self.extract_text_from_image(image_path)
                print(f"ğŸ” OCRçµæœé•·åº¦: {len(extracted_text) if extracted_text else 0}")
                
                if extracted_text:
                    # å°‡æå–çš„æ–‡å­—æ ¼å¼åŒ–ä¸¦æ›¿æ›åœ–ç‰‡å¼•ç”¨
                    formatted_text = f"\n\n**[å¾åœ–ç‰‡æå–çš„æ–‡å­—]**\n{extracted_text}\n\n"
                    modified = True
                    
                    # ğŸ’¾ ä¿ç•™åœ–ç‰‡æª”æ¡ˆä»¥ä¾›debugï¼ˆä¸åˆªé™¤ï¼‰
                    print(f"ğŸ–¼ï¸  å·²è™•ç†åœ–ç‰‡æª”æ¡ˆ: {image_filename}ï¼ˆä¿ç•™åŸæª”æ¡ˆä¾›debugï¼‰")
                    
                    return formatted_text
                else:
                    print(f"âš ï¸  OCRç„¡æ³•æå–æ–‡å­—ï¼Œä¿ç•™åŸåœ–ç‰‡å¼•ç”¨")
                    # å¦‚æœç„¡æ³•æå–æ–‡å­—ï¼Œä¿ç•™åŸå§‹åœ–ç‰‡å¼•ç”¨
                    return match.group(0)
            else:
                print(f"âš ï¸  æ‰¾ä¸åˆ°åœ–ç‰‡æª”æ¡ˆ: {image_path}")
                return match.group(0)
        
        # æ›¿æ›æ‰€æœ‰åœ–ç‰‡å¼•ç”¨
        print(f"ğŸ”„ é–‹å§‹æ›¿æ›åœ–ç‰‡å¼•ç”¨...")
        processed_content = re.sub(image_pattern, replace_image_with_text, content)
        
        # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå¯«å›åŸå§‹æ–‡ä»¶
        if modified:
            print(f"ğŸ’¾ å¯«å›ä¿®æ”¹å¾Œçš„æª”æ¡ˆ...")
            with open(md_file_path, 'w', encoding='utf-8') as f:
                f.write(processed_content)
            print(f"âœ… å·²æ›´æ–°åŸå§‹ Markdown æ–‡ä»¶: {md_file_path}")
        else:
            print(f"â„¹ï¸  æ²’æœ‰é€²è¡Œä»»ä½•ä¿®æ”¹")
        
        return modified
    
    def convert_md_to_json(self, md_file_path, output_dir):
        """å°‡Markdownæª”æ¡ˆè½‰æ›ç‚ºJSON"""
        try:
            print(f"ğŸ“„ é–‹å§‹è™•ç†: {md_file_path}")
            
            # è™•ç†åœ–ç‰‡ä¸­çš„æ–‡å­—ï¼ˆç›´æ¥ä¿®æ”¹åŸå§‹æ–‡ä»¶ï¼‰
            images_processed = self.process_images_in_markdown(md_file_path)
            
            # è®€å–ï¼ˆå¯èƒ½å·²ä¿®æ”¹çš„ï¼‰Markdownæª”æ¡ˆ
            with open(md_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æå…§å®¹
            self.parse_markdown_content(content)
            
            # å»ºç«‹JSONçµæ§‹
            json_structure = {
                "section": self.section,
                "groups": self.groups
            }
            
            # ç”Ÿæˆè¼¸å‡ºæª”å
            md_filename = Path(md_file_path).stem
            output_filename = Path(output_dir) / f"{md_filename}_converted.json"
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜JSONæª”æ¡ˆ
            with open(output_filename, 'w', encoding='utf-8') as f:
                json.dump(json_structure, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… è½‰æ›å®Œæˆ!")
            print(f"ğŸ“ JSONæª”æ¡ˆ: {output_filename}")
            print(f"ğŸ”¢ Section: {self.section}")
            print(f"ğŸ“Š Groupsæ•¸é‡: {len(self.groups)}")
            
            # é¡¯ç¤ºè™•ç†çµæœæ‘˜è¦
            total_items = sum(len(group['items']) for group in self.groups)
            print(f"ğŸ“‹ ç¸½é …ç›®æ•¸: {total_items}")
            
            if images_processed:
                print(f"ğŸ–¼ï¸  å·²è™•ç†åœ–ç‰‡ä¸¦æ›´æ–°åŸå§‹æ–‡ä»¶")
            
            return str(output_filename)
            
        except Exception as e:
            print(f"âŒ è½‰æ›å¤±æ•—: {str(e)}")
            return None
    
    def display_preview(self):
        """é¡¯ç¤ºè½‰æ›çµæœé è¦½"""
        if self.groups:
            print("\nğŸ” è½‰æ›çµæœé è¦½:")
            print("=" * 50)
            for i, group in enumerate(self.groups):
                print(f"\n{i+1}. {group['title']}")
                for item in group['items']:
                    clause = item['clause']
                    query = item['query'][:80] + "..." if len(item['query']) > 80 else item['query']
                    print(f"   â€¢ {clause}: {query}")
    
    def extract_items_from_ocr_text_enhanced(self, lines, start_index):
        """å¢å¼·ç‰ˆOCRæ–‡å­—è§£æï¼Œæ”¯æ´å¤šç¨®æ ¼å¼ï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
        items_groups = []
        i = start_index + 1
        
        # åˆä½µOCRæ–‡å­—å…§å®¹ï¼Œä¿ç•™æ›è¡Œç¬¦ä»¥ä¾¿åˆ†æ
        ocr_lines = []
        while i < len(lines) and lines[i].strip():
            ocr_lines.append(lines[i].strip())
            i += 1
        
        # ä¿ç•™è¡Œçµæ§‹å’Œåˆä½µæ–‡å­—å…©ç¨®ç‰ˆæœ¬
        ocr_text_with_lines = "\n".join(ocr_lines)
        ocr_text_merged = " ".join(ocr_lines)
        
        print(f"ğŸ” OCRæ–‡å­—è¡Œæ•¸: {len(ocr_lines)}")
        print(f"ğŸ” OCRå‰100å­—å…ƒ: {ocr_text_merged[:100]}...")
        
        # æ–¹æ³•1: åŸºæ–¼å¯¦éš›OCRæ–‡å­—è§£æ
        parsed_groups = self.parse_ocr_content(ocr_text_merged)
        if parsed_groups:
            items_groups.extend(parsed_groups)
            print(f"âœ… OCRè§£ææˆåŠŸï¼Œæå–äº† {len(parsed_groups)} å€‹ç¾¤çµ„")
            return items_groups, i
        
        # æ–¹æ³•2: æª¢æ¸¬ç°¡å–®çš„a.ã€b.ã€c.æ ¼å¼ï¼ˆOCRå¸¸è¦‹æ ¼å¼ï¼‰
        # å„ªå…ˆä½¿ç”¨ä¿ç•™è¡Œçµæ§‹çš„ç‰ˆæœ¬
        simple_items = self.extract_simple_letter_items_from_ocr(ocr_text_with_lines)
        if not simple_items:
            # å¦‚æœå¤±æ•—ï¼Œå†å˜—è©¦åˆä½µç‰ˆæœ¬
            simple_items = self.extract_simple_letter_items_from_ocr(ocr_text_merged)
            
        if simple_items:
            # å˜—è©¦å¾ä¸Šä¸‹æ–‡ä¸­ç²å–æ­éœ²é …ç›®ç·¨è™Ÿ
            disclosure_number = self.extract_disclosure_number_from_context_enhanced(lines, start_index)
            
            # å˜—è©¦å¾ä¸Šä¸‹æ–‡ä¸­æå–æ¨™é¡Œ
            title = self.extract_title_from_context(lines, start_index, disclosure_number)
            
            # è½‰æ›ç‚ºæ­£ç¢ºçš„JSONæ ¼å¼
            formatted_items = []
            for item in simple_items:
                formatted_items.append({
                    "clause": f"{disclosure_number} {item['letter']}",
                    "query": item['content']
                })
            
            group = {
                "title": f"{disclosure_number} {title}",
                "items": formatted_items
            }
            items_groups.append(group)
            print(f"âœ… ç°¡å–®æ ¼å¼OCRæå–äº† {len(simple_items)} å€‹é …ç›®")
            return items_groups, i
        
        # æ–¹æ³•3: å°‹æ‰¾æ˜ç¢ºçš„æ­éœ²é …ç›®æ¨™è­˜
        disclosure_patterns = [
            r'æ­éœ²é …ç›®\s*(\d+-\d+)(?:çš„æŒ‡å¼•|.*?)',
            r'(\d+-\d+)\s*([^ã€‚]{10,50})',  # ç°¡å–®çš„ç·¨è™Ÿ+æ¨™é¡Œæ¨¡å¼
        ]
        
        found_disclosures = []
        for pattern in disclosure_patterns:
            matches = re.finditer(pattern, ocr_text_merged)
            for match in matches:
                disclosure_number = match.group(1)
                # ç¢ºèªç·¨è™Ÿç¬¦åˆç•¶å‰section
                if disclosure_number.startswith(self.section):
                    found_disclosures.append((disclosure_number, match.start(), match.end()))
        
        if found_disclosures:
            print(f"ğŸ¯ åœ¨OCRä¸­æ‰¾åˆ° {len(found_disclosures)} å€‹æ­éœ²é …ç›®")
            for disclosure_number, start_pos, end_pos in found_disclosures:
                # æå–è©²æ­éœ²é …ç›®çš„ç›¸é—œæ–‡å­—
                items = self.parse_disclosure_from_ocr_segment(ocr_text_merged, disclosure_number, start_pos)
                if items:
                    # æå–æ¨™é¡Œ
                    title = self.extract_title_from_ocr(ocr_text_merged, disclosure_number)
                    group = {
                        "title": f"{disclosure_number} {title}",
                        "items": items
                    }
                    items_groups.append(group)
        else:
            print("âŒ åœ¨OCRæ–‡å­—ä¸­æ²’æœ‰æ‰¾åˆ°æ¨™æº–æ ¼å¼çš„æ­éœ²é …ç›®ï¼Œå˜—è©¦å…¶ä»–è§£ææ–¹æ³•...")
            # æ–¹æ³•4: åŸºæ–¼è¦æ±‚æ–‡å­—çµæ§‹è§£æ
            other_items = self.parse_ocr_requirements(ocr_text_merged)
            if other_items:
                items_groups.extend(other_items)
        
        return items_groups, i
    
    def parse_ocr_content(self, ocr_text):
        """åŸºæ–¼å¯¦éš›OCRå…§å®¹è§£æï¼Œä¸é€²è¡Œæ¨æ–·æˆ–è£œå…¨"""
        groups = []
        
        # æ­¥é©Ÿ1: æª¢æ¸¬æ˜¯å¦åŒ…å«"è¦æ±‚"å’Œ"å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š"
        if not re.search(r'è¦æ±‚.*å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š|å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š.*è¦æ±‚', ocr_text):
            return groups
        
        print("ğŸ¯ æª¢æ¸¬åˆ°æ¨™æº–çš„è¦æ±‚æ ¼å¼ï¼Œæå–å¯¦éš›å­˜åœ¨çš„é …ç›®")
        
        # æ­¥é©Ÿ2: æå–æ­éœ²é …ç›®ç·¨è™Ÿï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        disclosure_number = self.extract_disclosure_number_from_ocr(ocr_text)
        if not disclosure_number:
            disclosure_number = f"{self.section}-?"  # ç„¡æ³•ç¢ºå®šæ™‚ä½¿ç”¨å•è™Ÿ
        
        # æ­¥é©Ÿ3: åªæå–å¯¦éš›å­˜åœ¨çš„é …ç›®ï¼Œä¸é€²è¡Œè£œå…¨
        existing_items = self.extract_existing_items_from_ocr(ocr_text)
        
        # æ­¥é©Ÿ4: ç›´æ¥ä½¿ç”¨æå–åˆ°çš„é …ç›®ï¼Œä¸è£œå…¨ç¼ºå¤±é …ç›®
        complete_items = []
        for item in existing_items:
            complete_items.append({
                "clause": f"{disclosure_number} {item['letter']}",
                "query": item['content']
            })
        
        if complete_items:
            # å˜—è©¦å¾OCRæ–‡å­—ä¸­æå–æ¨™é¡Œ
            title = self.extract_title_from_ocr(ocr_text, disclosure_number)
            group = {
                "title": f"{disclosure_number} {title}",
                "items": complete_items
            }
            groups.append(group)
            print(f"âœ… æå–äº† {disclosure_number}ï¼Œå…± {len(complete_items)} å€‹å¯¦éš›é …ç›®")
        
        return groups
    
    def extract_disclosure_number_from_ocr(self, ocr_text):
        """å¾OCRæ–‡å­—ä¸­æå–æ­éœ²é …ç›®ç·¨è™Ÿ"""
        # å˜—è©¦å¤šç¨®æ¨¡å¼
        patterns = [
            rf'æ­éœ²é …ç›®\s*({self.section}-\d+)',
            rf'({self.section}-\d+)\s*çš„æŒ‡å¼•',
            rf'({self.section}-\d+)',  # æœ€å¾Œå˜—è©¦ä»»ä½•ç¬¦åˆçš„ç·¨è™Ÿ
        ]
        
        for pattern in patterns:
            match = re.search(pattern, ocr_text)
            if match:
                return match.group(1)
        
        return None
    
    def extract_existing_items_from_ocr(self, ocr_text):
        """å¾OCRæ–‡å­—ä¸­æå–å·²å­˜åœ¨çš„é …ç›®"""
        items = []
        
        # å°‹æ‰¾ a., b., c., d., e. æ ¼å¼çš„é …ç›®
        item_pattern = r'([a-e])\.\s*([^a-e\.]{10,}?)(?=[a-e]\.|æŒ‡å¼•|ä¾‹å¦‚|$)'
        matches = re.finditer(item_pattern, ocr_text, re.DOTALL)
        
        for match in matches:
            letter = match.group(1)
            content = self.clean_text(match.group(2))
            
            # æ¸…ç†å…§å®¹ï¼Œç§»é™¤ä¸ç›¸é—œçš„ç‰‡æ®µ
            content = self.clean_ocr_item_content(content)
            
            if len(content) > 10:  # ç¢ºä¿å…§å®¹è¶³å¤ é•·
                items.append({
                    'letter': letter,
                    'content': content,
                    'found_in_ocr': True
                })
                print(f"   ğŸ“Œ æ‰¾åˆ°OCRé …ç›® {letter}: {content[:50]}...")
        
        return items
    
    def clean_ocr_item_content(self, content):
        """æ¸…ç†OCRé …ç›®å…§å®¹"""
        # ç§»é™¤å¸¸è¦‹çš„OCRéŒ¯èª¤å’Œç„¡é—œæ–‡å­—
        content = re.sub(r'æŒ‡å¼•.*$', '', content)  # ç§»é™¤"æŒ‡å¼•"å¾Œçš„å…§å®¹
        content = re.sub(r'ä¾‹å¦‚[:ï¼š].*$', '', content)  # ç§»é™¤"ä¾‹å¦‚:"å¾Œçš„å…§å®¹
        content = re.sub(r'æ­éœ²é …ç›®.*$', '', content)  # ç§»é™¤"æ­éœ²é …ç›®"å¾Œçš„å…§å®¹
        content = re.sub(r'\s+', ' ', content)  # åˆä½µå¤šå€‹ç©ºæ ¼
        content = content.strip(' ,ï¼Œã€‚.;ï¼›')  # ç§»é™¤çµå°¾çš„æ¨™é»ç¬¦è™Ÿ
        
        return content
    
    def extract_title_from_ocr(self, ocr_text, disclosure_number):
        """å¾OCRæ–‡å­—ä¸­å¯¦éš›æå–æ¨™é¡Œï¼Œä¸ä½¿ç”¨é è¨­å°æ‡‰"""
        # å˜—è©¦å¾OCRæ–‡å­—ä¸­å°‹æ‰¾æ¨™é¡Œ
        title_patterns = [
            rf'æ­éœ²é …ç›®\s*{re.escape(disclosure_number)}\s*(.+?)(?:è¦æ±‚|æŒ‡å¼•|$)',
            rf'{re.escape(disclosure_number)}\s*(.+?)(?:è¦æ±‚|æŒ‡å¼•|$)',
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, ocr_text)
            if match:
                title = self.clean_text(match.group(1))
                if title and len(title) > 3:  # ç¢ºä¿æ¨™é¡Œæœ‰æ„ç¾©
                    return title
        
        # å¦‚æœç„¡æ³•å¾OCRæå–æ¨™é¡Œï¼Œè¿”å›ç©ºå­—ä¸²
        return ""
    
    def parse_disclosure_from_ocr_segment(self, text, disclosure_number, start_pos):
        """å¾OCRæ–‡å­—æ®µè½ä¸­è§£æç‰¹å®šæ­éœ²é …ç›®çš„è¦æ±‚"""
        items = []
        
        # å°‹æ‰¾è¦æ±‚éƒ¨åˆ†
        requirements_patterns = [
            r'è¦æ±‚[ï¼š:]?\s*å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š[ï¼š:]?\s*([^æŒ‡å¼•]+)',
            r'å ±å°çµ„ç¹”æ‡‰å ±å°ä»¥ä¸‹è³‡è¨Š[ï¼š:]?\s*([^æŒ‡å¼•]+)',
            r'è¦æ±‚[ï¼š:]?\s*(.+?)(?:æŒ‡å¼•|å»ºè­°|èƒŒæ™¯|$)',
        ]
        
        for pattern in requirements_patterns:
            match = re.search(pattern, text[start_pos:start_pos+1000])  # é™åˆ¶æœå°‹ç¯„åœ
            if match:
                requirements_text = match.group(1)
                print(f"ğŸ“‹ æ‰¾åˆ°è¦æ±‚æ–‡å­—: {requirements_text[:100]}...")
                
                # è§£æè¦æ±‚ä¸­çš„é …ç›®
                items = self.parse_requirements_from_text_enhanced(requirements_text, disclosure_number)
                if items:
                    print(f"ğŸ“Š æˆåŠŸè§£æå‡º {len(items)} å€‹é …ç›®")
                    break
        
        return items
    
    def parse_requirements_from_text_enhanced(self, text, disclosure_number):
        """å¢å¼·ç‰ˆè¦æ±‚æ–‡å­—è§£æ"""
        items = []
        
        # æ–¹æ³•1: æ¨™æº–çš„ a. b. c. æ ¼å¼
        item_pattern = r'([a-e])\.\s*([^a-e\.]{20,}?)(?=[a-e]\.|$)'
        matches = re.finditer(item_pattern, text, re.DOTALL)
        
        for match in matches:
            clause_letter = match.group(1)
            item_text = self.clean_text(match.group(2))
            
            if len(item_text) > 10:  # éæ¿¾å¤ªçŸ­çš„å…§å®¹
                items.append({
                    "clause": f"{disclosure_number} {clause_letter}",
                    "query": item_text
                })
        
        # æ–¹æ³•2: å¦‚æœæ²’æ‰¾åˆ°æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦å…¶ä»–æ¨¡å¼
        if not items:
            # å˜—è©¦å°‹æ‰¾å…¶ä»–åˆ†å‰²æ¨¡å¼ï¼ˆå¦‚åˆ†è™Ÿã€å¥è™Ÿç­‰ï¼‰
            segments = re.split(r'[ï¼›;ã€‚]\s*', text)
            for i, segment in enumerate(segments):
                segment = self.clean_text(segment)
                if len(segment) > 20:  # è¶³å¤ é•·çš„æ®µè½
                    items.append({
                        "clause": f"{disclosure_number} {chr(97+i)}",  # a, b, c...
                        "query": segment
                    })
                    if i >= 4:  # æœ€å¤š5å€‹é …ç›® (a-e)
                        break
        
        return items
    
    def parse_ocr_requirements(self, ocr_text):
        """åŸºæ–¼è¦æ±‚æ–‡å­—çµæ§‹è§£æ"""
        items_groups = []
        
        # åŸºæ–¼æ–‡å­—çµæ§‹å°‹æ‰¾æ­éœ²é …ç›®
        # æ¨¡å¼ï¼šå°‹æ‰¾å¯èƒ½çš„é …ç›®ç·¨è™Ÿå’Œæè¿°
        
        # å…ˆå˜—è©¦æ‰¾åˆ°ä»»ä½•çœ‹èµ·ä¾†åƒè¦æ±‚çš„æ–‡å­—æ®µè½
        requirement_indicators = [
            r'è¦æ±‚.*?å ±å°.*?è³‡è¨Š',
            r'å ±å°çµ„ç¹”æ‡‰å ±å°',
            r'æ‡‰å ±å°ä»¥ä¸‹',
        ]
        
        for pattern in requirement_indicators:
            matches = re.finditer(pattern, ocr_text, re.IGNORECASE)
            for match in matches:
                # æå–è¦æ±‚å‘¨åœçš„æ–‡å­—
                start_pos = max(0, match.start() - 50)
                end_pos = min(len(ocr_text), match.end() + 500)
                requirement_segment = ocr_text[start_pos:end_pos]
                
                # å˜—è©¦å¾é€™å€‹æ®µè½ä¸­æå–é …ç›®
                items = self.extract_items_from_segment(requirement_segment)
                if items:
                    # å¾ä¸Šä¸‹æ–‡ä¸­æå–æ­éœ²é …ç›®ç·¨è™Ÿ
                    disclosure_number = self.extract_disclosure_number_from_context(ocr_text, match.start())
                    title = self.extract_title_from_ocr(ocr_text, disclosure_number)
                    
                    group = {
                        "title": f"{disclosure_number} {title}",
                        "items": items
                    }
                    items_groups.append(group)
                    break  # æ‰¾åˆ°ä¸€å€‹å°±åœæ­¢
        
        return items_groups
    
    def extract_items_from_segment(self, segment):
        """å¾æ–‡å­—æ®µè½ä¸­æå–é …ç›®"""
        items = []
        
        # å˜—è©¦å¤šç¨®åˆ†å‰²æ–¹å¼
        split_patterns = [
            r'[a-e]\.\s*',  # a. b. c.
            r'[ï¼›;]\s*',    # åˆ†è™Ÿåˆ†å‰²
            r'[ã€‚]\s*',     # å¥è™Ÿåˆ†å‰²
            r'[ï¼š]\s*',    # å†’è™Ÿåˆ†å‰²
        ]
        
        for pattern in split_patterns:
            segments = re.split(pattern, segment)
            if len(segments) > 1:  # æ‰¾åˆ°äº†åˆ†å‰²
                for i, seg in enumerate(segments[1:], 1):  # è·³éç¬¬ä¸€å€‹ç©ºæ®µ
                    seg = self.clean_text(seg)
                    if len(seg) > 15:  # è¶³å¤ é•·çš„å…§å®¹
                        items.append({
                            "clause": f"{self.section}-? {chr(96+i)}",  # æœªçŸ¥é …ç›®ç·¨è™Ÿ
                            "query": seg
                        })
                        if i >= 5:  # æœ€å¤š5å€‹é …ç›®
                            break
                if items:
                    break  # å¦‚æœæ‰¾åˆ°äº†é …ç›®å°±åœæ­¢å˜—è©¦å…¶ä»–æ¨¡å¼
        
        return items
    
    def extract_disclosure_number_from_context(self, text, position):
        """å¾ä¸Šä¸‹æ–‡ä¸­æå–æ­éœ²é …ç›®ç·¨è™Ÿ"""
        # åœ¨ä½ç½®å‘¨åœå°‹æ‰¾å¯èƒ½çš„ç·¨è™Ÿ
        search_range = text[max(0, position-100):position+100]
        
        # å°‹æ‰¾ XXX-X æ ¼å¼çš„ç·¨è™Ÿ
        number_pattern = rf'({self.section}-\d+)'
        match = re.search(number_pattern, search_range)
        if match:
            return match.group(1)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›æœªçŸ¥æ ¼å¼
        return f"{self.section}-?"
    
    def detect_mixed_format_disclosure(self, lines, current_index):
        """æª¢æ¸¬æ··åˆæ ¼å¼çš„æ­éœ²é …ç›®ï¼ˆéæ¨™æº–ä½†æœ‰çµæ§‹çš„æ ¼å¼ï¼‰"""
        line = lines[current_index].strip()
        
        # æª¢æ¸¬å¯èƒ½çš„æ ¼å¼è®ŠåŒ–
        # ä¾‹å¦‚ï¼šæŸäº›æ ¼å¼å¯èƒ½æ¨™é¡Œå’Œå…§å®¹åœ¨åŒä¸€è¡Œï¼Œæˆ–è€…æ ¼å¼ç•¥æœ‰ä¸åŒ
        
        # é€™è£¡å¯ä»¥æ·»åŠ æ›´å¤šæ··åˆæ ¼å¼çš„æª¢æ¸¬é‚è¼¯
        # ç›®å‰è¿”å›ç©ºçµæœ
        return False, []
    
    def is_strong_section_end(self, line):
        """æª¢æŸ¥æ˜¯å¦æ˜¯å¼·çƒˆçš„å€æ®µçµæŸä¿¡è™Ÿï¼ˆæ¯”is_requirements_section_endæ›´åš´æ ¼ï¼‰"""
        # åªæœ‰åœ¨é‡åˆ°æ˜ç¢ºçš„å¤§æ¨™é¡Œæˆ–æ–°sectionæ™‚æ‰èªç‚ºæ˜¯çµæŸ
        strong_end_patterns = [
            r"^#+\s*(å»ºè­°|æŒ‡å¼•|èƒŒæ™¯)",  # æ˜ç¢ºçš„æ¨™é¡Œï¼ˆç§»é™¤å½™ç·¨è¦æ±‚ï¼‰
            r"^æ­éœ²é …ç›®\s*\*\*\d+-\d+\*\*",     # æ–°çš„æ­éœ²é …ç›®æ¨™é¡Œ
            r"^#.*æ­éœ²é …ç›®.*\d+-\d+",            # å…¶ä»–æ­éœ²é …ç›®æ ¼å¼
        ]
        
        for pattern in strong_end_patterns:
            if re.search(pattern, line):
                return True
        return False
    
    def is_deep_indented_item(self, lines, current_index, disclosure_number):
        """æª¢æŸ¥æ˜¯å¦æ˜¯æ·±å±¤ç¸®é€²é …ç›®çµæ§‹ï¼ˆå¦‚ 403-9 aï¼‰"""
        line = lines[current_index].strip()
        
        # æª¢æŸ¥ç•¶å‰è¡Œæ˜¯å¦æ˜¯å†’è™Ÿå‰ç½®æ ¼å¼ï¼ˆå¦‚ "æ‰€æœ‰å“¡å·¥: **a.**"ï¼‰
        if re.search(r'(.+?)[ï¼š:]\s*\*\*([a-e])\.\*\*\s*$', line):
            # æª¢æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æœ‰ç¸®é€²çš„ç¾…é¦¬æ•¸å­—
            if current_index + 1 < len(lines):
                next_line = lines[current_index + 1]
                if (next_line.startswith('\t') and 
                    re.search(r'\*\*([ivx]+)\.\*\*', next_line.strip())):
                    return True
        
        return False
    
    def extract_deep_indented_item(self, lines, current_index, disclosure_number):
        """æå–æ·±å±¤ç¸®é€²é …ç›®ï¼ˆç‰¹åˆ¥è™•ç† 403-9 a é€™æ¨£çš„çµæ§‹ï¼‰"""
        line = lines[current_index].strip()
        
        # è§£æä¸»é …ç›®
        match = re.search(r'(.+?)[ï¼š:]\s*\*\*([a-e])\.\*\*\s*$', line)
        if not match:
            return None, current_index + 1
        
        main_content = self.clean_text(match.group(1))
        clause_letter = match.group(2)
        
        print(f"   ğŸ¯ æ‰¾åˆ°æ·±å±¤ç¸®é€²ä¸»é …ç›®: {disclosure_number} {clause_letter} - {main_content[:50]}...")
        
        # æ”¶é›†ç¸®é€²çš„å­é …ç›®
        subitems = []
        i = current_index + 1
        
        while i < len(lines):
            subline = lines[i].strip()
            original_line = lines[i]
            
            # è·³éç©ºè¡Œ
            if not subline:
                i += 1
                continue
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯ç¸®é€²çš„å­é …ç›®
            if original_line.startswith('\t'):
                subitem_text = self.extract_roman_subitem(subline)
                if subitem_text:
                    subitems.append(subitem_text)
                    print(f"     ğŸ“Œ æ·±å±¤å­é …ç›®: {subitem_text[:50]}...")
                    i += 1
                    continue
            
            # å¦‚æœé‡åˆ°ä¸ç¸®é€²çš„è¡Œï¼Œæª¢æŸ¥æ˜¯å¦æ˜¯æ–°çš„ä¸»é …ç›®
            if self.is_main_item(subline) or self.is_new_disclosure_item(subline):
                print(f"     â¹ï¸  æ·±å±¤ç¸®é€²åœæ­¢ï¼Œé‡åˆ°: {subline[:50]}...")
                break
            
            i += 1
        
        # çµ„åˆæœ€çµ‚çµæœ
        if subitems:
            subitems_text = "ã€".join(subitems)
            final_query = f"{main_content}:{subitems_text}"
        else:
            final_query = main_content
        
        item = {
            "clause": f"{disclosure_number} {clause_letter}",
            "query": final_query
        }
        
        print(f"   âœ… æ·±å±¤ç¸®é€²åˆä½µçµæœ: {item['query']}")
        
        return item, i
    
    def extract_simple_letter_items_from_ocr(self, ocr_text):
        """å¾OCRæ–‡å­—ä¸­æå–ç°¡å–®çš„å­—æ¯é …ç›®æ ¼å¼ï¼ˆa.ã€b.ã€c.ç­‰ï¼‰"""
        items = []
        
        print(f"ğŸ” åˆ†æç°¡å–®å­—æ¯æ ¼å¼é …ç›®...")
        
        # æŒ‰è¡Œåˆ†å‰²OCRæ–‡å­—é€²è¡Œè™•ç†
        lines = ocr_text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯ç°¡å–®çš„å­—æ¯é …ç›®æ ¼å¼
            # æ”¯æ´: "a. å…§å®¹", "b. å…§å®¹" ç­‰
            simple_item_match = re.match(r'^([a-e])\.\s*(.+)', line)
            if simple_item_match:
                letter = simple_item_match.group(1)
                content = simple_item_match.group(2).strip()
                
                # æ¸…ç†å…§å®¹
                content = self.clean_text(content)
                if len(content) > 10:  # ç¢ºä¿å…§å®¹è¶³å¤ é•·
                    items.append({
                        "letter": letter,
                        "content": content
                    })
                    print(f"   ğŸ“Œ æ‰¾åˆ°ç°¡å–®é …ç›® {letter}: {content[:50]}...")
        
        # å¦‚æœæ²’æ‰¾åˆ°åˆ†è¡Œçš„æ ¼å¼ï¼Œå˜—è©¦åœ¨æ•´å€‹æ–‡å­—ä¸­å°‹æ‰¾
        if not items:
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…æ‰€æœ‰a.ã€b.ã€c.æ ¼å¼
            # æ”¹é€²ï¼šä½¿ç”¨æ›´ç²¾ç¢ºçš„æ­£å‰‡è¡¨é”å¼ä¾†åˆ†é›¢é …ç›®
            pattern = r'([a-e])\.\s*([^a-e\.]*?)(?=\s*[a-e]\.|$)'
            matches = re.finditer(pattern, ocr_text, re.DOTALL)
            
            for match in matches:
                letter = match.group(1)
                content = self.clean_text(match.group(2))
                
                # é€²ä¸€æ­¥æ¸…ç†å…§å®¹ï¼Œç§»é™¤ä¸‹ä¸€å€‹é …ç›®çš„é–‹é ­
                content = re.sub(r'\s*[a-e]\.\s.*$', '', content, flags=re.DOTALL)
                content = content.strip(' .ï¼Œã€‚')
                
                if len(content) > 10:
                    items.append({
                        "letter": letter,
                        "content": content
                    })
                    print(f"   ğŸ“Œ æ‰¾åˆ°é€£çºŒé …ç›® {letter}: {content[:50]}...")
        
        return items
    
    def extract_disclosure_number_from_context_enhanced(self, lines, ocr_start_index):
        """å¾OCRæ–‡å­—å‘¨åœçš„ä¸Šä¸‹æ–‡ä¸­æå–æ­éœ²é …ç›®ç·¨è™Ÿï¼ˆå¢å¼·ç‰ˆï¼‰"""
        # å‘ä¸Šæœå°‹æœ€è¿‘çš„æ­éœ²é …ç›®æ¨™é¡Œ
        for i in range(ocr_start_index - 1, max(0, ocr_start_index - 10), -1):
            line = lines[i].strip()
            
            # å°‹æ‰¾æ­éœ²é …ç›®æ¨™é¡Œ
            disclosure_patterns = [
                rf'æ­éœ²é …ç›®\s*\*\*({self.section}-\d+)\*\*',
                rf'æ­éœ²é …ç›®\s*({self.section}-\d+)',
                rf'#+\s*æ­éœ²é …ç›®\s*\*\*({self.section}-\d+)\*\*',
                rf'#+\s*æ­éœ²é …ç›®\s*({self.section}-\d+)',
            ]
            
            for pattern in disclosure_patterns:
                match = re.search(pattern, line)
                if match:
                    disclosure_number = match.group(1)
                    print(f"ğŸ¯ å¾ä¸Šä¸‹æ–‡æ‰¾åˆ°æ­éœ²é …ç›®ç·¨è™Ÿ: {disclosure_number}")
                    return disclosure_number
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›æœªçŸ¥æ ¼å¼
        return f"{self.section}-?"
    
    def extract_title_from_context(self, lines, ocr_start_index, disclosure_number):
        """å¾OCRæ–‡å­—å‘¨åœçš„ä¸Šä¸‹æ–‡ä¸­æå–æ¨™é¡Œ"""
        # å‘ä¸Šæœå°‹æœ€è¿‘çš„æ­éœ²é …ç›®æ¨™é¡Œ
        for i in range(ocr_start_index - 1, max(0, ocr_start_index - 10), -1):
            line = lines[i].strip()
            
            # å°‹æ‰¾åŒ…å«disclosure_numberçš„æ¨™é¡Œè¡Œ
            title_patterns = [
                rf'#+\s*æ­éœ²é …ç›®\s*\*\*{re.escape(disclosure_number)}\*\*\s*(.+)',
                rf'#+\s*æ­éœ²é …ç›®\s*{re.escape(disclosure_number)}\s*(.+)',
                rf'æ­éœ²é …ç›®\s*\*\*{re.escape(disclosure_number)}\*\*\s*(.+)',
                rf'æ­éœ²é …ç›®\s*{re.escape(disclosure_number)}\s*(.+)',
            ]
            
            for pattern in title_patterns:
                match = re.search(pattern, line)
                if match:
                    title = self.clean_text(match.group(1))
                    print(f"ğŸ¯ å¾ä¸Šä¸‹æ–‡æ‰¾åˆ°æ¨™é¡Œ: {title}")
                    return title
        
        # å¦‚æœæ‰¾ä¸åˆ°æ¨™é¡Œï¼Œè¿”å›é è¨­å€¼
        return "æœªçŸ¥é …ç›®"

def main():
    parser = argparse.ArgumentParser(description='å°‡GRI PDFæª”æ¡ˆè½‰æ›ç‚ºJSONæ ¼å¼ï¼ˆåŒ…å«PDFâ†’MDâ†’JSONå®Œæ•´æµç¨‹ï¼‰')
    parser.add_argument('--input_pdf_dir', default='input_pdf', help='è¼¸å…¥PDFæª”æ¡ˆçš„ç›®éŒ„')
    parser.add_argument('--md_dir', default='pdf_to_md', help='ä¸­é–“Markdownæª”æ¡ˆçš„ç›®éŒ„')
    parser.add_argument('--output_dir', default='output_json', help='è¼¸å‡ºJSONæª”æ¡ˆçš„ç›®éŒ„')
    parser.add_argument('--skip_pdf_conversion', action='store_true', help='è·³éPDFè½‰æ›æ­¥é©Ÿï¼Œç›´æ¥è™•ç†å·²å­˜åœ¨çš„Markdownæª”æ¡ˆ')
    
    args = parser.parse_args()
    
    print("ğŸš€ GRI PDFè½‰JSONå®Œæ•´æµç¨‹å•Ÿå‹•!")
    print("=" * 60)
    
    input_pdf_dir = Path(args.input_pdf_dir)
    md_dir = Path(args.md_dir)
    output_dir = Path(args.output_dir)
    
    # ğŸ†• è‡ªå‹•å‰µå»ºå¿…è¦çš„ç›®éŒ„
    print("\nğŸ“ æª¢æŸ¥ä¸¦å‰µå»ºå¿…è¦çš„ç›®éŒ„...")
    
    # æª¢æŸ¥ä¸¦å‰µå»º pdf_to_md ç›®éŒ„
    if not md_dir.exists():
        print(f"ğŸ“‚ å‰µå»º Markdown ç›®éŒ„: {md_dir}")
        md_dir.mkdir(parents=True, exist_ok=True)
    else:
        print(f"âœ… Markdown ç›®éŒ„å·²å­˜åœ¨: {md_dir}")
    
    # æª¢æŸ¥ä¸¦å‰µå»º output_json ç›®éŒ„
    if not output_dir.exists():
        print(f"ğŸ“‚ å‰µå»º JSON è¼¸å‡ºç›®éŒ„: {output_dir}")
        output_dir.mkdir(parents=True, exist_ok=True)
    else:
        print(f"âœ… JSON è¼¸å‡ºç›®éŒ„å·²å­˜åœ¨: {output_dir}")
    
    # æª¢æŸ¥ä¸¦å‰µå»º input_pdf ç›®éŒ„ï¼ˆå¦‚æœéœ€è¦é€²è¡ŒPDFè½‰æ›ï¼‰
    if not args.skip_pdf_conversion and not input_pdf_dir.exists():
        print(f"ğŸ“‚ å‰µå»º PDF è¼¸å…¥ç›®éŒ„: {input_pdf_dir}")
        input_pdf_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ’¡ è«‹å°‡è¦è½‰æ›çš„PDFæª”æ¡ˆæ”¾å…¥ {input_pdf_dir} ç›®éŒ„ä¸­")
    
    # æ­¥é©Ÿ1: PDFè½‰Markdownï¼ˆå¦‚æœæ²’æœ‰è·³éçš„è©±ï¼‰
    if not args.skip_pdf_conversion:
        print("\nğŸ“‹ æ­¥é©Ÿ1: PDFè½‰Markdown")
        print("-" * 40)
        
        # æª¢æŸ¥input_pdfç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not input_pdf_dir.exists():
            print(f"âŒ è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {input_pdf_dir}")
            return
        
        # æŸ¥æ‰¾æ‰€æœ‰PDFæª”æ¡ˆ
        pdf_files = list(input_pdf_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"âŒ åœ¨ {input_pdf_dir} ä¸­æ²’æœ‰æ‰¾åˆ° .pdf æª”æ¡ˆ")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(pdf_files)} å€‹PDFæª”æ¡ˆ:")
        for pdf_file in pdf_files:
            print(f"   â€¢ {pdf_file.name}")
        
        # ä½¿ç”¨markerè½‰æ›æ‰€æœ‰PDFï¼ˆç›®éŒ„å·²åœ¨å‰é¢å‰µå»ºï¼‰
        print(f"\nğŸ”„ ä½¿ç”¨markerè½‰æ›PDFæª”æ¡ˆ...")
        try:
            import subprocess
            result = subprocess.run([
                'marker', str(input_pdf_dir), '--output_dir', str(md_dir)
            ], capture_output=True, text=True, cwd=str(Path.cwd()))
            
            if result.returncode == 0:
                print("âœ… PDFè½‰æ›å®Œæˆ!")
                print(f"ğŸ“ Markdownæª”æ¡ˆå·²ä¿å­˜åˆ°: {md_dir}")
            else:
                print(f"âŒ PDFè½‰æ›å¤±æ•—: {result.stderr}")
                return
                
        except FileNotFoundError:
            print("âŒ æ‰¾ä¸åˆ°markeræŒ‡ä»¤ï¼Œè«‹ç¢ºèªmarkerå·²æ­£ç¢ºå®‰è£")
            print("ğŸ’¡ æ‚¨å¯ä»¥ä½¿ç”¨ --skip_pdf_conversion åƒæ•¸è·³éæ­¤æ­¥é©Ÿ")
            return
        except Exception as e:
            print(f"âŒ PDFè½‰æ›éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return
    else:
        print("\nâ­ï¸  è·³éPDFè½‰æ›æ­¥é©Ÿï¼Œç›´æ¥è™•ç†å·²å­˜åœ¨çš„Markdownæª”æ¡ˆ")
    
    # æ­¥é©Ÿ2: Markdownè½‰JSONï¼ˆåŒ…å«OCRè™•ç†ï¼‰
    print("\nğŸ“‹ æ­¥é©Ÿ2: Markdownè½‰JSONï¼ˆåŒ…å«OCRåœ–ç‰‡è™•ç†ï¼‰")
    print("-" * 50)
    
    # æŸ¥æ‰¾æ‰€æœ‰markdownæª”æ¡ˆ
    md_files = list(md_dir.rglob("*.md"))
    
    if not md_files:
        print(f"âŒ åœ¨ {md_dir} ä¸­æ²’æœ‰æ‰¾åˆ° .md æª”æ¡ˆ")
        print("ğŸ’¡ è«‹ç¢ºèªPDFè½‰æ›æ­¥é©Ÿæ˜¯å¦æˆåŠŸå®Œæˆ")
        return
    
    print(f"ğŸ“„ æ‰¾åˆ° {len(md_files)} å€‹Markdownæª”æ¡ˆ:")
    for md_file in md_files:
        print(f"   â€¢ {md_file}")
    
    # è™•ç†æ¯å€‹markdownæª”æ¡ˆï¼ˆç›®éŒ„å·²åœ¨å‰é¢å‰µå»ºï¼‰
    success_count = 0
    total_items = 0
    
    for md_file in md_files:
        print(f"\nğŸ”„ è™•ç†æª”æ¡ˆ: {md_file}")
        print("-" * 30)
        
        converter = GRIMarkdownToJsonConverter()
        result = converter.convert_md_to_json(md_file, output_dir)
        
        if result:
            converter.display_preview()
            print(f"âœ… {md_file.name} -> {Path(result).name}")
            success_count += 1
            total_items += sum(len(group['items']) for group in converter.groups)
        else:
            print(f"âŒ è™•ç†å¤±æ•—: {md_file.name}")
    
    # æœ€çµ‚çµ±è¨ˆ
    print("\n" + "=" * 60)
    print("ğŸ‰ å®Œæ•´æµç¨‹è™•ç†å®Œæˆ!")
    print(f"ğŸ“Š è™•ç†çµ±è¨ˆ:")
    print(f"   â€¢ æˆåŠŸè™•ç†: {success_count}/{len(md_files)} å€‹æª”æ¡ˆ")
    print(f"   â€¢ ç¸½æå–é …ç›®æ•¸: {total_items}")
    print(f"ğŸ“ JSONæª”æ¡ˆå·²ä¿å­˜åˆ°: {output_dir}")
    
    # åˆ—å‡ºç”Ÿæˆçš„JSONæª”æ¡ˆ
    json_files = list(output_dir.glob("*.json"))
    if json_files:
        print(f"\nğŸ“‹ ç”Ÿæˆçš„JSONæª”æ¡ˆ:")
        for json_file in json_files:
            print(f"   â€¢ {json_file.name}")
    
    print("\nâœ¨ æ‰€æœ‰ä»»å‹™å®Œæˆ! æ‚¨å¯ä»¥åœ¨output_jsonç›®éŒ„ä¸­æŸ¥çœ‹è½‰æ›çµæœã€‚")

if __name__ == "__main__":
    main() 